{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import emoji\n",
    "from sklearn.feature_extraction.text import CountVectorizer #TF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Tf-idf\n",
    "from string import punctuation #signos de puntuacion\n",
    "from sklearn.model_selection import train_test_split #otorgar pesos para w2v\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HATE                                         COMENTARIO\n",
       "0   0.0  ¿Ya vieron que en la #AO habrá evento por el #...\n",
       "1   0.0  muy XD que para el primer punto exiges que Yam...\n",
       "2   0.0  Apoco lees?\\n1-El primer punto es para hablar ...\n",
       "3   0.0  vos se nota que no tenes compresión lectora xD...\n",
       "4   0.0  No, literalmente Kaido y todos los piratas bes..."
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"DATOS_UNICOS_TOTALES.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('stopwords1.txt', 'r', encoding = 'utf-8')\n",
    "stopwords_1 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_words = list(punctuation)\n",
    "#we add spanish punctuation\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "   # sw = stopwords.words('spanish') #Use your favorite stopwords list\n",
    "    text = emoji.demojize(str(text))\n",
    "    urls = []\n",
    "    for i in text.split():\n",
    "        if not i.startswith('http'):\n",
    "            urls.append(i)\n",
    "    text1 = ' '.join(urls)\n",
    "    cl1 = re.findall(r'[^¿@#&?\\w+][\\w+]+',text1)\n",
    "    text2 = ' '.join(cl1)\n",
    "    cl3 = re.findall(r'[a-zA-Záéíóúñ\\s:_]+',text2)\n",
    "    text3 = ' '.join(cl3)\n",
    "    text4 = text.lower()\n",
    "    c = text4.maketrans('áéíóú','aeiou')\n",
    "    text5 = text4.translate(c)\n",
    "    L = [palabra for palabra in text5.split() if len(palabra) >2 and palabra not in stopwords_1]\n",
    "    return ' '.join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "# remove links from tweets\n",
    "    text = clean(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\":\", \"\", text)\n",
    "    # remove punctuation\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # remove repeated characters\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    # tokenize\n",
    "    tokens =  word_tokenize(text)\n",
    "    return \" \".join(tokens) #para w2v se junta las palabras sino se usa solo return tokens tf idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "      <td>ya ao habra evento pride enserio rifan mostran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "      <td>primer punto exiges yamato autoproclame hombre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "      <td>apoco les el primer punto hablar yamato usa pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "      <td>nota tenes compresion lectora diciendo hipocri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "      <td>literalmente kaido piratas bestia incluso lufy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>felizmente o jiang cheng não é gay\\n\\né pan e ...</td>\n",
       "      <td>felizmente jiang cheng não gay pan ace faz del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...</td>\n",
       "      <td>votacion super masiva comenten veces meta come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A portarnos mal mal mal</td>\n",
       "      <td>portarnos mal mal mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El sábado 26 ya podemos ir sin mascarilla...\\n...</td>\n",
       "      <td>sabado podemos mascarila alguien sabe que camb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El grito de puto no conlleva un problema socia...</td>\n",
       "      <td>grito puto conleva problema social detras futb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14279 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HATE                                         COMENTARIO  \\\n",
       "0       0.0  ¿Ya vieron que en la #AO habrá evento por el #...   \n",
       "1       0.0  muy XD que para el primer punto exiges que Yam...   \n",
       "2       0.0  Apoco lees?\\n1-El primer punto es para hablar ...   \n",
       "3       0.0  vos se nota que no tenes compresión lectora xD...   \n",
       "4       0.0  No, literalmente Kaido y todos los piratas bes...   \n",
       "...     ...                                                ...   \n",
       "14274   0.0  felizmente o jiang cheng não é gay\\n\\né pan e ...   \n",
       "14275   0.0   VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...   \n",
       "14276   0.0                            A portarnos mal mal mal   \n",
       "14277   0.0  El sábado 26 ya podemos ir sin mascarilla...\\n...   \n",
       "14278   0.0  El grito de puto no conlleva un problema socia...   \n",
       "\n",
       "                                            Texto Limpio  \n",
       "0      ya ao habra evento pride enserio rifan mostran...  \n",
       "1      primer punto exiges yamato autoproclame hombre...  \n",
       "2      apoco les el primer punto hablar yamato usa pr...  \n",
       "3      nota tenes compresion lectora diciendo hipocri...  \n",
       "4      literalmente kaido piratas bestia incluso lufy...  \n",
       "...                                                  ...  \n",
       "14274  felizmente jiang cheng não gay pan ace faz del...  \n",
       "14275  votacion super masiva comenten veces meta come...  \n",
       "14276                              portarnos mal mal mal  \n",
       "14277  sabado podemos mascarila alguien sabe que camb...  \n",
       "14278  grito puto conleva problema social detras futb...  \n",
       "\n",
       "[14279 rows x 3 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Texto Limpio'] = df['COMENTARIO'].apply(tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "      <td>ya ao habra evento pride enserio rifan mostran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "      <td>primer punto exiges yamato autoproclame hombre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "      <td>apoco les el primer punto hablar yamato usa pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "      <td>nota tenes compresion lectora diciendo hipocri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "      <td>literalmente kaido piratas bestia incluso lufy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HATE                                         COMENTARIO  \\\n",
       "0   0.0  ¿Ya vieron que en la #AO habrá evento por el #...   \n",
       "1   0.0  muy XD que para el primer punto exiges que Yam...   \n",
       "2   0.0  Apoco lees?\\n1-El primer punto es para hablar ...   \n",
       "3   0.0  vos se nota que no tenes compresión lectora xD...   \n",
       "4   0.0  No, literalmente Kaido y todos los piratas bes...   \n",
       "\n",
       "                                        Texto Limpio  \n",
       "0  ya ao habra evento pride enserio rifan mostran...  \n",
       "1  primer punto exiges yamato autoproclame hombre...  \n",
       "2  apoco les el primer punto hablar yamato usa pr...  \n",
       "3  nota tenes compresion lectora diciendo hipocri...  \n",
       "4  literalmente kaido piratas bestia incluso lufy...  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ver nota haz leido manga ela nunca dice identifica genero masculino sino autoproclama oden diferente sobre kaido piratas bestias teoria mas logica cercana asi decirlo verdad kaido quiere'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Texto Limpio'].values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(df[\"Texto Limpio\"].values)\n",
    "np.savetxt(\"Comentarios_limpios_W2V.txt\",df2,fmt=\"%s\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_hate = df[df[\"HATE\"]==0]\n",
    "df_hate = df[df[\"HATE\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "      <td>ya ao habra evento pride enserio rifan mostran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "      <td>primer punto exiges yamato autoproclame hombre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "      <td>apoco les el primer punto hablar yamato usa pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "      <td>nota tenes compresion lectora diciendo hipocri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "      <td>literalmente kaido piratas bestia incluso lufy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>felizmente o jiang cheng não é gay\\n\\né pan e ...</td>\n",
       "      <td>felizmente jiang cheng não gay pan ace faz del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...</td>\n",
       "      <td>votacion super masiva comenten veces meta come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A portarnos mal mal mal</td>\n",
       "      <td>portarnos mal mal mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El sábado 26 ya podemos ir sin mascarilla...\\n...</td>\n",
       "      <td>sabado podemos mascarila alguien sabe que camb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El grito de puto no conlleva un problema socia...</td>\n",
       "      <td>grito puto conleva problema social detras futb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13766 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HATE                                         COMENTARIO  \\\n",
       "0       0.0  ¿Ya vieron que en la #AO habrá evento por el #...   \n",
       "1       0.0  muy XD que para el primer punto exiges que Yam...   \n",
       "2       0.0  Apoco lees?\\n1-El primer punto es para hablar ...   \n",
       "3       0.0  vos se nota que no tenes compresión lectora xD...   \n",
       "4       0.0  No, literalmente Kaido y todos los piratas bes...   \n",
       "...     ...                                                ...   \n",
       "14274   0.0  felizmente o jiang cheng não é gay\\n\\né pan e ...   \n",
       "14275   0.0   VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...   \n",
       "14276   0.0                            A portarnos mal mal mal   \n",
       "14277   0.0  El sábado 26 ya podemos ir sin mascarilla...\\n...   \n",
       "14278   0.0  El grito de puto no conlleva un problema socia...   \n",
       "\n",
       "                                            Texto Limpio  \n",
       "0      ya ao habra evento pride enserio rifan mostran...  \n",
       "1      primer punto exiges yamato autoproclame hombre...  \n",
       "2      apoco les el primer punto hablar yamato usa pr...  \n",
       "3      nota tenes compresion lectora diciendo hipocri...  \n",
       "4      literalmente kaido piratas bestia incluso lufy...  \n",
       "...                                                  ...  \n",
       "14274  felizmente jiang cheng não gay pan ace faz del...  \n",
       "14275  votacion super masiva comenten veces meta come...  \n",
       "14276                              portarnos mal mal mal  \n",
       "14277  sabado podemos mascarila alguien sabe que camb...  \n",
       "14278  grito puto conleva problema social detras futb...  \n",
       "\n",
       "[13766 rows x 3 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((504, 3), (13766, 3))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hate.shape, df_no_hate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando train / teste (0.8 - 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 3)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_train = df_hate[:403].sample(403)\n",
    "hate_train.dropna(how=\"any\",inplace=True)\n",
    "hate_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 3)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_test = df_hate[403:].sample(101)\n",
    "hate_test.dropna(how=\"any\",inplace=True)\n",
    "hate_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 3)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_train = df_no_hate[:10000].sample(403)\n",
    "no_hate_train.dropna(how=\"any\",inplace=True)\n",
    "no_hate_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 3)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_test = df_no_hate[10000:].sample(101)\n",
    "no_hate_test.dropna(how=\"any\",inplace=True)\n",
    "no_hate_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Eres necio igual el valor aumentará con el eje...</td>\n",
       "      <td>necio igual valor aumentara ejemplo gama alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Yo entiendo perfectamente a los del LGBT con l...</td>\n",
       "      <td>entiendo perfectamente lgbt progenitor luz esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Indignación pena de muerte para los malditos q...</td>\n",
       "      <td>indignacion pena muerte malditos hicieron losi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@elmundoes Ya que leo a mucho retrasado por aq...</td>\n",
       "      <td>elmundoes leo retrasado aquisi colectivo lgtb ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Lo Mundo \\n\\n¿Ya no puede haber mujeres guapas...</td>\n",
       "      <td>mundo ya puede haber mujeres guapas tienen tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>help mi compañera volvió a subir un estado sob...</td>\n",
       "      <td>help compañera volvio subir lgbt intente respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @FsaSnchez: Las leyes LGTBI NO perjudican a...</td>\n",
       "      <td>fsasnchez leyes lgtbi perjudican nadie nada ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @FueraCloset_AC: Marsha P. Johnson fue una ...</td>\n",
       "      <td>fueraclosetac marsha johnson mujer trans afroa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Difícilmente vemos artistas de la comunidad ho...</td>\n",
       "      <td>dificilmente vemos artistas comunidad hoy dia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Porque tenés problemas en la cabeza</td>\n",
       "      <td>tenes problemas cabeza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HATE                                         COMENTARIO  \\\n",
       "4001   0.0  Eres necio igual el valor aumentará con el eje...   \n",
       "7661   0.0  Yo entiendo perfectamente a los del LGBT con l...   \n",
       "2078   0.0  Indignación pena de muerte para los malditos q...   \n",
       "9284   0.0  @elmundoes Ya que leo a mucho retrasado por aq...   \n",
       "2551   0.0  Lo Mundo \\n\\n¿Ya no puede haber mujeres guapas...   \n",
       "...    ...                                                ...   \n",
       "5507   0.0  help mi compañera volvió a subir un estado sob...   \n",
       "9199   0.0  RT @FsaSnchez: Las leyes LGTBI NO perjudican a...   \n",
       "5950   0.0  RT @FueraCloset_AC: Marsha P. Johnson fue una ...   \n",
       "8315   0.0  Difícilmente vemos artistas de la comunidad ho...   \n",
       "3924   0.0                Porque tenés problemas en la cabeza   \n",
       "\n",
       "                                           Texto Limpio  \n",
       "4001      necio igual valor aumentara ejemplo gama alta  \n",
       "7661  entiendo perfectamente lgbt progenitor luz esp...  \n",
       "2078  indignacion pena muerte malditos hicieron losi...  \n",
       "9284  elmundoes leo retrasado aquisi colectivo lgtb ...  \n",
       "2551  mundo ya puede haber mujeres guapas tienen tod...  \n",
       "...                                                 ...  \n",
       "5507  help compañera volvio subir lgbt intente respo...  \n",
       "9199  fsasnchez leyes lgtbi perjudican nadie nada ob...  \n",
       "5950  fueraclosetac marsha johnson mujer trans afroa...  \n",
       "8315  dificilmente vemos artistas comunidad hoy dia ...  \n",
       "3924                             tenes problemas cabeza  \n",
       "\n",
       "[403 rows x 3 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = word2vec.Text8Corpus(\"Comentarios_limpios_W2V.txt\")\n",
    "modelo_w2v = word2vec.Word2Vec(lineas,vector_size=100,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08266481,  1.0524025 ,  0.41026938,  0.25375807, -0.0379312 ,\n",
       "       -1.0030138 ,  0.32316712,  1.5184793 , -0.20965141, -0.44294193,\n",
       "       -0.29299033, -0.82212406,  0.16941388,  0.5464219 ,  0.5225356 ,\n",
       "       -0.56156063,  0.40623194, -0.8471191 ,  0.09019951, -1.6246331 ,\n",
       "       -0.03056568,  0.7462683 ,  0.5375891 , -0.41512778, -0.4509439 ,\n",
       "       -0.22942495, -0.5996057 , -0.8370876 , -0.27085555,  0.13423917,\n",
       "        0.6849064 , -0.01971593, -0.03688022, -0.60302705, -0.27275902,\n",
       "        0.95572644,  0.6031194 , -0.5162545 , -0.26717344, -1.8689078 ,\n",
       "        0.37452844, -0.92998314, -0.4240036 , -0.19026895,  0.7950656 ,\n",
       "       -0.24603929, -0.631464  , -0.09616642,  0.33975846,  0.27464142,\n",
       "        0.6116903 , -0.9528366 , -0.8350961 , -0.607857  , -0.69494957,\n",
       "        0.52139455,  0.49089485, -0.00678391, -0.63658017, -0.18441041,\n",
       "        0.3901802 ,  0.33133364, -0.1396486 ,  0.21418317, -0.8704476 ,\n",
       "        0.4740383 , -0.12792909,  0.2840477 , -1.2416211 ,  0.39417276,\n",
       "       -0.64471054,  0.9821178 ,  1.1238674 , -0.16253541,  0.21788467,\n",
       "        0.4514139 ,  0.0083101 ,  0.10348164, -1.4081908 ,  0.5209678 ,\n",
       "       -0.15383737, -0.36783102, -0.43494567,  0.8464515 ,  0.06305482,\n",
       "        0.240152  , -0.11131533,  0.87653303,  1.5421783 ,  0.20778899,\n",
       "        0.9026639 ,  0.58062106, -0.04509005,  0.32004827,  1.5911912 ,\n",
       "        0.55597335,  0.09885422, -0.8302404 ,  0.39947078, -0.39046156],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_w2v.wv['odio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para obtener vector promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFV(documento):\n",
    "    L = []\n",
    "    words = documento.split()\n",
    "    L = np.array([modelo_w2v.wv[w] for w in words if w in modelo_w2v.wv.key_to_index])\n",
    "    if len(L):\n",
    "        return np.mean(L,axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07516111,  1.2887101 ,  0.5058344 ,  0.32913685, -0.07426248,\n",
       "       -1.2469305 ,  0.41615015,  1.8823106 , -0.27465904, -0.5598468 ,\n",
       "       -0.3384861 , -1.0070968 ,  0.20385297,  0.6761592 ,  0.6533015 ,\n",
       "       -0.66822994,  0.4957426 , -1.0574832 ,  0.10746388, -2.0163426 ,\n",
       "       -0.02854263,  0.9023453 ,  0.6755773 , -0.5051832 , -0.5483347 ,\n",
       "       -0.29372373, -0.7231561 , -1.0213407 , -0.34059256,  0.14948055,\n",
       "        0.8552903 , -0.02868301, -0.01817648, -0.7400613 , -0.3256756 ,\n",
       "        1.1741438 ,  0.7668966 , -0.6305844 , -0.32811219, -2.306719  ,\n",
       "        0.4538585 , -1.1518452 , -0.5388058 , -0.24549827,  0.9847609 ,\n",
       "       -0.29037535, -0.7801807 , -0.08608226,  0.41625324,  0.36887163,\n",
       "        0.7317445 , -1.1565012 , -1.0624638 , -0.7471266 , -0.8369434 ,\n",
       "        0.6291903 ,  0.61353254, -0.0257061 , -0.8074565 , -0.23142919,\n",
       "        0.47571504,  0.41368693, -0.18307471,  0.2678793 , -1.0765547 ,\n",
       "        0.6053419 , -0.15661956,  0.3424408 , -1.5322435 ,  0.491436  ,\n",
       "       -0.80468196,  1.2063423 ,  1.3841882 , -0.19864373,  0.2704952 ,\n",
       "        0.52442545,  0.01928758,  0.13006529, -1.7212653 ,  0.6393744 ,\n",
       "       -0.16410401, -0.4575314 , -0.53192014,  1.0621874 ,  0.08639033,\n",
       "        0.29183918, -0.14163221,  1.0937858 ,  1.9077549 ,  0.26628655,\n",
       "        1.107444  ,  0.71781266, -0.04150635,  0.42019743,  1.9750438 ,\n",
       "        0.68825567,  0.09272881, -1.0409563 ,  0.48368466, -0.49037254],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFV(\"odio gay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando la función getFV a todos los comentarios del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train_FV = hate_train[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "no_hate_train_FV = no_hate_train[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "hate_test_FV = hate_test[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "no_hate_test_FV = no_hate_test[\"Texto Limpio\"].apply(lambda x: getFV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_train[\"HATE\"] = 1\n",
    "hate_test[\"HATE\"] = 1\n",
    "no_hate_train[\"HATE\"] = 0\n",
    "no_hate_test[\"HATE\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10636    [-0.04194131, 0.7361186, 0.28461733, 0.1849813...\n",
       "11871    [-0.019084197, 0.2674242, 0.100409254, 0.06732...\n",
       "12936    [-0.05054014, 0.97768104, 0.37357825, 0.250920...\n",
       "11051    [-0.045718495, 0.80294317, 0.31522688, 0.20861...\n",
       "12528    [-0.040887747, 0.661663, 0.25535932, 0.1647123...\n",
       "                               ...                        \n",
       "14151    [-0.03300957, 0.59748304, 0.23533702, 0.157288...\n",
       "13991    [-0.043042, 0.60026777, 0.23113547, 0.15474221...\n",
       "13823    [-0.03151353, 0.55830705, 0.21616195, 0.145333...\n",
       "10383    [-0.05038712, 0.8457672, 0.32239375, 0.2233799...\n",
       "11396    [-0.046549626, 0.75612086, 0.29240257, 0.19778...\n",
       "Name: Texto Limpio, Length: 101, dtype: object"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_test_FV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 100)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((hate_train_FV.tolist(),no_hate_train_FV.tolist()),axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806,)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.concatenate((hate_train[\"HATE\"].values,no_hate_train[\"HATE\"].values),axis=0)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 100)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.concatenate((hate_test_FV.tolist(),no_hate_test_FV.tolist()),axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202,)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = np.concatenate((hate_test[\"HATE\"].values,no_hate_test[\"HATE\"].values),axis=0)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.0001)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificador = svm.SVC(gamma=0.0001,C=1000)\n",
    "#clasificador = svm.SVC()\n",
    "clasificador.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clasificador.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6237623762376238"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61       101\n",
      "           1       0.61      0.66      0.64       101\n",
      "\n",
      "    accuracy                           0.62       202\n",
      "   macro avg       0.62      0.62      0.62       202\n",
      "weighted avg       0.62      0.62      0.62       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clasificador.predict(getFV(\"me gustaria que te mueras puto gay\").reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
