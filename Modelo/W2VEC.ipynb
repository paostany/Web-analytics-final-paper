{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize #tokenizar\n",
    "import emoji \n",
    "from sklearn.feature_extraction.text import CountVectorizer #TF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Tf-idf\n",
    "from string import punctuation #signos de puntuacion\n",
    "from sklearn.model_selection import train_test_split #otorgar pesos para w2v\n",
    "from gensim.models import word2vec #para aplicar word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HATE                                         COMENTARIO\n",
       "0   0.0  ¿Ya vieron que en la #AO habrá evento por el #...\n",
       "1   0.0  muy XD que para el primer punto exiges que Yam...\n",
       "2   0.0  Apoco lees?\\n1-El primer punto es para hablar ...\n",
       "3   0.0  vos se nota que no tenes compresión lectora xD...\n",
       "4   0.0  No, literalmente Kaido y todos los piratas bes..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"DATOS_UNICOS_TOTALES.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('stopwords1.txt', 'r', encoding = 'utf-8')\n",
    "stopwords_1 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_words = list(punctuation) #lista de signos de puntuacion\n",
    "#we add spanish punctuation\n",
    "non_words.extend(['¿', '¡']) #se extiende la lista para agregar dos signos mas\n",
    "non_words.extend(map(str,range(10))) #se extiende la lista para agregar numeros del 1 al 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de texto\n",
    "def clean(text):\n",
    "    text = emoji.demojize(str(text)) #convierte los emojis en texto\n",
    "    urls = []\n",
    "    for i in text.split():\n",
    "        if not i.startswith('http'): #se quitan las palabras que empiecen con http\n",
    "            urls.append(i)\n",
    "    text1 = ' '.join(urls)\n",
    "    cl1 = re.findall(r'[^¿@#&?\\w+][\\w+]+',text1) #quitamos caracteres especiales\n",
    "    text2 = ' '.join(cl1)\n",
    "    cl3 = re.findall(r'[a-zA-Záéíóúñ\\s:_]+',text2) #nos quedamos con palabras que contengan el siguiente patrón\n",
    "    text3 = ' '.join(cl3)\n",
    "    text4 = text.lower()\n",
    "    c = text4.maketrans('áéíóú','aeiou') #se cambia las vocales con tílde a vocales sin tilde\n",
    "    text5 = text4.translate(c)\n",
    "    text = re.sub(r\"lgbt\", \"\", text5) #se reemplaza la etiqueta lgbt\n",
    "    text = re.sub(r\"lgbti\", \"\", text) # se reemplaza la etiqueta lgbti\n",
    "    #L = [palabra for palabra in text5.split() if len(palabra) >2 and palabra not in stopwords_1]\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): #tokenizar cada comentario\n",
    "    text = clean(text) #se aplica la limpieza anterior\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #se vuelve a limpiar para reemplazar las palabras que tengan ese patrón\n",
    "    text = re.sub(r\":\", \"\", text) #se reemplaza : por nada\n",
    "    text = ''.join([c for c in text if c not in non_words]) #Se quitan todos los signos de puntuacion incluidas en la librería\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text) #se remueven caracteres repetidos\n",
    "    tokens =  word_tokenize(text) #se tokeniza\n",
    "    return ' '.join(tokens) #para w2v se junta las palabras sino se usa solo return tokens tf-idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "      <td>ya vieron que en la ao habra evento por el pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "      <td>muy xd que para el primer punto exiges que yam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "      <td>apoco les el primer punto es para hablar de po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "      <td>vos se nota que no tenes compresion lectora xd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "      <td>no literalmente kaido y todos los piratas best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>felizmente o jiang cheng não é gay\\n\\né pan e ...</td>\n",
       "      <td>felizmente o jiang cheng não e gay e pan e ace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...</td>\n",
       "      <td>votacion super masiva comenten o veces meta co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A portarnos mal mal mal</td>\n",
       "      <td>a portarnos mal mal mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El sábado 26 ya podemos ir sin mascarilla...\\n...</td>\n",
       "      <td>el sabado ya podemos ir sin mascarila alguien ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>El grito de puto no conlleva un problema socia...</td>\n",
       "      <td>el grito de puto no conleva un problema social...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14279 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HATE                                         COMENTARIO  \\\n",
       "0       0.0  ¿Ya vieron que en la #AO habrá evento por el #...   \n",
       "1       0.0  muy XD que para el primer punto exiges que Yam...   \n",
       "2       0.0  Apoco lees?\\n1-El primer punto es para hablar ...   \n",
       "3       0.0  vos se nota que no tenes compresión lectora xD...   \n",
       "4       0.0  No, literalmente Kaido y todos los piratas bes...   \n",
       "...     ...                                                ...   \n",
       "14274   0.0  felizmente o jiang cheng não é gay\\n\\né pan e ...   \n",
       "14275   0.0   VOTACIÓN SUPER MASIVA   \\n\\nCOMENTEN 100 o 20...   \n",
       "14276   0.0                            A portarnos mal mal mal   \n",
       "14277   0.0  El sábado 26 ya podemos ir sin mascarilla...\\n...   \n",
       "14278   0.0  El grito de puto no conlleva un problema socia...   \n",
       "\n",
       "                                            Texto Limpio  \n",
       "0      ya vieron que en la ao habra evento por el pri...  \n",
       "1      muy xd que para el primer punto exiges que yam...  \n",
       "2      apoco les el primer punto es para hablar de po...  \n",
       "3      vos se nota que no tenes compresion lectora xd...  \n",
       "4      no literalmente kaido y todos los piratas best...  \n",
       "...                                                  ...  \n",
       "14274  felizmente o jiang cheng não e gay e pan e ace...  \n",
       "14275  votacion super masiva comenten o veces meta co...  \n",
       "14276                            a portarnos mal mal mal  \n",
       "14277  el sabado ya podemos ir sin mascarila alguien ...  \n",
       "14278  el grito de puto no conleva un problema social...  \n",
       "\n",
       "[14279 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Texto Limpio'] = df['COMENTARIO'].apply(tokenize) #se aplica la función tokenize que incluye la limpieza a cada comentario\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>¿Ya vieron que en la #AO habrá evento por el #...</td>\n",
       "      <td>ya vieron que en la ao habra evento por el pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>muy XD que para el primer punto exiges que Yam...</td>\n",
       "      <td>muy xd que para el primer punto exiges que yam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apoco lees?\\n1-El primer punto es para hablar ...</td>\n",
       "      <td>apoco les el primer punto es para hablar de po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>vos se nota que no tenes compresión lectora xD...</td>\n",
       "      <td>vos se nota que no tenes compresion lectora xd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>No, literalmente Kaido y todos los piratas bes...</td>\n",
       "      <td>no literalmente kaido y todos los piratas best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HATE                                         COMENTARIO  \\\n",
       "0   0.0  ¿Ya vieron que en la #AO habrá evento por el #...   \n",
       "1   0.0  muy XD que para el primer punto exiges que Yam...   \n",
       "2   0.0  Apoco lees?\\n1-El primer punto es para hablar ...   \n",
       "3   0.0  vos se nota que no tenes compresión lectora xD...   \n",
       "4   0.0  No, literalmente Kaido y todos los piratas bes...   \n",
       "\n",
       "                                        Texto Limpio  \n",
       "0  ya vieron que en la ao habra evento por el pri...  \n",
       "1  muy xd que para el primer punto exiges que yam...  \n",
       "2  apoco les el primer punto es para hablar de po...  \n",
       "3  vos se nota que no tenes compresion lectora xd...  \n",
       "4  no literalmente kaido y todos los piratas best...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean(df['Texto Limpio'].values[6949])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(df[\"Texto Limpio\"].values)\n",
    "np.savetxt(\"Comentarios_limpios_W2V.txt\",df2,fmt=\"%s\",encoding=\"utf-8\") #se guarda el dataframe limpio para que luego sea usado en word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se separa en dos dataframes, uno con discursos etiquetados como odio y otro con los comentarios de no odio.\n",
    "df_no_hate = df[df[\"HATE\"]==0]\n",
    "df_hate = df[df[\"HATE\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Esto es la máxima imbecilidad</td>\n",
       "      <td>esto es la maxima imbecilidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>No nos engañemos. Los homosexuales bien sabemo...</td>\n",
       "      <td>no nos engañemos los homosexuales bien sabemos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Claro que es ilegal.\\nSi esa fuera la razón, c...</td>\n",
       "      <td>claro que es ilegal si esa fuera la razon clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A los curas pro MOVIMIENTO LGTBI+ deberían ser...</td>\n",
       "      <td>a los curas pro movimiento lgtbi deberian ser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A los de siempre. Hablo del Movimiento, de la ...</td>\n",
       "      <td>a los de siempre hablo del movimiento de la ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14157</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@13Azulcrema Y eso que cabrón? Si allá está pe...</td>\n",
       "      <td>azulcrema y eso que cabron si ala esta penado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14181</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cuchame, soy la mierda más delulu que te puede...</td>\n",
       "      <td>cuchame soy la mierda mas delulu que te puedes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@NEXWAL999 tampoco te las harías pq eres gay</td>\n",
       "      <td>nexwal tampoco te las harias pq eres gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Not mi amiga diciéndome que ha ido a comer sol...</td>\n",
       "      <td>not mi amiga diciendome que ha ido a comer sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>¿Yo dije que por un gay se destruye la familia ?</td>\n",
       "      <td>yo dije que por un gay se destruye la familia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HATE                                         COMENTARIO  \\\n",
       "15      1.0                      Esto es la máxima imbecilidad   \n",
       "46      1.0  No nos engañemos. Los homosexuales bien sabemo...   \n",
       "52      1.0  Claro que es ilegal.\\nSi esa fuera la razón, c...   \n",
       "89      1.0  A los curas pro MOVIMIENTO LGTBI+ deberían ser...   \n",
       "90      1.0  A los de siempre. Hablo del Movimiento, de la ...   \n",
       "...     ...                                                ...   \n",
       "14157   1.0  @13Azulcrema Y eso que cabrón? Si allá está pe...   \n",
       "14181   1.0  Cuchame, soy la mierda más delulu que te puede...   \n",
       "14182   1.0       @NEXWAL999 tampoco te las harías pq eres gay   \n",
       "14203   1.0  Not mi amiga diciéndome que ha ido a comer sol...   \n",
       "14234   1.0   ¿Yo dije que por un gay se destruye la familia ?   \n",
       "\n",
       "                                            Texto Limpio  \n",
       "15                         esto es la maxima imbecilidad  \n",
       "46     no nos engañemos los homosexuales bien sabemos...  \n",
       "52     claro que es ilegal si esa fuera la razon clar...  \n",
       "89     a los curas pro movimiento lgtbi deberian ser ...  \n",
       "90     a los de siempre hablo del movimiento de la ap...  \n",
       "...                                                  ...  \n",
       "14157  azulcrema y eso que cabron si ala esta penado ...  \n",
       "14181  cuchame soy la mierda mas delulu que te puedes...  \n",
       "14182           nexwal tampoco te las harias pq eres gay  \n",
       "14203  not mi amiga diciendome que ha ido a comer sol...  \n",
       "14234      yo dije que por un gay se destruye la familia  \n",
       "\n",
       "[504 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((504, 3), (13766, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hate.shape, df_no_hate.shape #Se puede observar las dimensiones de cada dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando train / teste (0.8 - 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se saca los comentarios clasificados como hate para el entrenamiento (80%)\n",
    "hate_train = df_hate[:403].sample(400)\n",
    "hate_train.dropna(how=\"any\",inplace=True)\n",
    "hate_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se saca los comentarios clasificados como hate para el testeo (20%)\n",
    "hate_test = df_hate[403:].sample(100)\n",
    "hate_test.dropna(how=\"any\",inplace=True)\n",
    "hate_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se saca los comentarios clasificados como no hate para el entrenamiento (80%)\n",
    "no_hate_train = df_no_hate[:10000].sample(400)\n",
    "no_hate_train.dropna(how=\"any\",inplace=True)\n",
    "no_hate_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se saca los comentarios clasificados como no hate para el testeo (20%)\n",
    "no_hate_test = df_no_hate[10000:].sample(100)\n",
    "no_hate_test.dropna(how=\"any\",inplace=True)\n",
    "no_hate_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HATE</th>\n",
       "      <th>COMENTARIO</th>\n",
       "      <th>Texto Limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>es que recuerdo por ejemplo personajes de la p...</td>\n",
       "      <td>es que recuerdo por ejemplo personajes de la p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Hace rato andaba de chismosa en un chat gay y ...</td>\n",
       "      <td>hace rato andaba de chismosa en un chat gay y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>asique discriminando a los osos eh...</td>\n",
       "      <td>asique discriminando a los osos eh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@MiguelA45290236 @MYMALK4PON3 No soy gay, es p...</td>\n",
       "      <td>miguela mymalkpon no soy gay es para apoyar a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Menuda mierder</td>\n",
       "      <td>menuda mierder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Igualmente estoy de acuerdo con las personas q...</td>\n",
       "      <td>igualmente estoy de acuerdo con las personas q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>CHAU FLFNFLFNFMKD\\n@Y4T0SKHLOROM</td>\n",
       "      <td>chau flfnflfnfmkd ytskhlorom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Esto es una pesadilla. Juegan con nuestra volu...</td>\n",
       "      <td>esto es una pesadila juegan con nuestra volunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Literal a nadie le importa una mierda,ni que h...</td>\n",
       "      <td>literal a nadie le importa una mierdani que hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@fantbue11 @Matiolas58 Maricon</td>\n",
       "      <td>fantbue matiolas maricon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HATE                                         COMENTARIO  \\\n",
       "1030   0.0  es que recuerdo por ejemplo personajes de la p...   \n",
       "9971   0.0  Hace rato andaba de chismosa en un chat gay y ...   \n",
       "2138   0.0              asique discriminando a los osos eh...   \n",
       "7048   0.0  @MiguelA45290236 @MYMALK4PON3 No soy gay, es p...   \n",
       "4554   0.0                                     Menuda mierder   \n",
       "...    ...                                                ...   \n",
       "2863   0.0  Igualmente estoy de acuerdo con las personas q...   \n",
       "1636   0.0                   CHAU FLFNFLFNFMKD\\n@Y4T0SKHLOROM   \n",
       "5130   0.0  Esto es una pesadilla. Juegan con nuestra volu...   \n",
       "2826   0.0  Literal a nadie le importa una mierda,ni que h...   \n",
       "9536   0.0                     @fantbue11 @Matiolas58 Maricon   \n",
       "\n",
       "                                           Texto Limpio  \n",
       "1030  es que recuerdo por ejemplo personajes de la p...  \n",
       "9971  hace rato andaba de chismosa en un chat gay y ...  \n",
       "2138                 asique discriminando a los osos eh  \n",
       "7048  miguela mymalkpon no soy gay es para apoyar a ...  \n",
       "4554                                     menuda mierder  \n",
       "...                                                 ...  \n",
       "2863  igualmente estoy de acuerdo con las personas q...  \n",
       "1636                       chau flfnflfnfmkd ytskhlorom  \n",
       "5130  esto es una pesadila juegan con nuestra volunt...  \n",
       "2826  literal a nadie le importa una mierdani que hu...  \n",
       "9536                           fantbue matiolas maricon  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = word2vec.Text8Corpus(\"Comentarios_limpios_W2V.txt\") #Se usa el txt anteriormente guardado que presenta los datos limpios\n",
    "modelo_w2v = word2vec.Word2Vec(lineas,vector_size=100,min_count=2) #Se aplica la tecnica word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21714494,  0.7032939 ,  0.09981456,  0.16321196,  0.2636095 ,\n",
       "       -0.7439507 ,  0.34549475,  1.3506867 , -0.6539837 , -0.6171259 ,\n",
       "       -0.14615037, -0.6687141 ,  0.10245548,  0.3436508 ,  0.24853788,\n",
       "       -0.5598931 ,  0.28244442, -0.1687612 , -0.4046003 , -1.2275983 ,\n",
       "        0.4587972 ,  0.14262539,  0.8236008 , -0.41751045, -0.14681716,\n",
       "        0.07000034, -0.45931533, -0.08844616, -0.57858753, -0.04277871,\n",
       "        0.4275727 , -0.2314186 ,  0.11620776, -0.78520846, -0.13842689,\n",
       "        0.4584956 ,  0.21420497,  0.1071602 , -0.22134042, -0.9055725 ,\n",
       "       -0.07672143, -0.7315552 , -0.5939882 ,  0.22811761,  0.4002627 ,\n",
       "       -0.3080911 , -0.47884065, -0.1695623 ,  0.39910364,  0.3628818 ,\n",
       "        0.41681492, -0.79096705, -0.01365972, -0.20807518, -0.41520938,\n",
       "        0.26859868,  0.49305695, -0.12976363, -0.6548134 ,  0.28610456,\n",
       "       -0.01905077, -0.11575596,  0.37693292,  0.0061153 , -0.23683777,\n",
       "        0.82976   , -0.01315832,  0.857942  , -1.0047011 ,  0.66132814,\n",
       "       -0.34516793,  0.43465477,  0.8587295 ,  0.04755804,  0.43824887,\n",
       "       -0.04547996, -0.13455336,  0.28045663, -0.6760798 , -0.27566686,\n",
       "       -0.5869557 , -0.16023049, -0.37257585,  0.5543605 ,  0.00291767,\n",
       "       -0.08405491,  0.4782387 , -0.05741023,  0.5252483 ,  0.198283  ,\n",
       "        0.7147907 ,  0.11313868,  0.10196013, -0.09049702,  0.96979487,\n",
       "        0.49233487,  0.08394822, -0.4824055 ,  0.06674977,  0.20403402],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_w2v.wv['odio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para obtener vector promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A través de esta función se saca el vector promedio caracteristico \n",
    "def getFV(documento):\n",
    "    L = []\n",
    "    words = documento.split()\n",
    "    L = np.array([modelo_w2v.wv[w] for w in words if w in modelo_w2v.wv.key_to_index])\n",
    "    if len(L):\n",
    "        return np.mean(L,axis=0) #se saca el promedio\n",
    "    else:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20250496,  0.793291  ,  0.01368177,  0.15764631,  0.21099919,\n",
       "       -0.91225994,  0.66633964,  1.5281088 , -0.6237575 , -0.8987496 ,\n",
       "       -0.11962215, -0.88339937,  0.02074496,  0.2111491 ,  0.11479285,\n",
       "       -0.52059376,  0.36559218, -0.35429475, -0.34665126, -1.4926498 ,\n",
       "        0.59418404,  0.32234916,  1.0212837 , -0.48982054,  0.00456946,\n",
       "        0.15918067, -0.7093687 , -0.13978262, -0.7527528 ,  0.15001726,\n",
       "        0.48150206, -0.12691979,  0.09807251, -1.1499437 , -0.2169351 ,\n",
       "        0.70608014,  0.18238142,  0.14836538, -0.32120264, -1.0161685 ,\n",
       "       -0.09691046, -0.8706307 , -0.6121837 ,  0.29985964,  0.46784088,\n",
       "       -0.57806945, -0.5220212 , -0.1451973 ,  0.49517235,  0.44497454,\n",
       "        0.4749779 , -0.7219528 , -0.05260438, -0.24259654, -0.45015216,\n",
       "        0.33543378,  0.5793189 , -0.30161273, -0.8086684 ,  0.5383253 ,\n",
       "       -0.09010372, -0.3082434 ,  0.510827  ,  0.10539587, -0.2589645 ,\n",
       "        0.8931618 , -0.20231837,  0.9168234 , -1.0619857 ,  0.69475555,\n",
       "       -0.35198456,  0.44200236,  1.0798297 , -0.05597833,  0.57851934,\n",
       "       -0.33272213,  0.01375718,  0.1954821 , -0.6399059 , -0.24282546,\n",
       "       -0.7007215 , -0.0489707 , -0.48825264,  0.6659131 , -0.05519373,\n",
       "       -0.23653437,  0.54491854,  0.31313998,  0.6356676 ,  0.09449016,\n",
       "        1.0584981 ,  0.3177045 ,  0.13645177, -0.06805196,  1.1013103 ,\n",
       "        0.45641565,  0.07546888, -0.5522809 , -0.01597765,  0.2944413 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFV(\"odio gay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando la función getFV a todos los comentarios del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se saca los vectores caracteristicos a cada df tanto de train y test.\n",
    "hate_train_FV = hate_train[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "no_hate_train_FV = no_hate_train[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "hate_test_FV = hate_test[\"Texto Limpio\"].apply(lambda x: getFV(x))\n",
    "no_hate_test_FV = no_hate_test[\"Texto Limpio\"].apply(lambda x: getFV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se estandariza las etiquetas a formato entero\n",
    "hate_train[\"HATE\"] = 1\n",
    "hate_test[\"HATE\"] = 1\n",
    "no_hate_train[\"HATE\"] = 0\n",
    "no_hate_test[\"HATE\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12879    [-0.21483359, 0.6934173, 0.08286718, 0.1658685...\n",
       "10954    [-0.15657318, 0.6691847, -0.07914188, 0.166235...\n",
       "10304    [-0.23139583, 0.7821595, -0.00905841, 0.138436...\n",
       "14192    [-0.111919336, 0.4961384, 0.026952114, 0.08916...\n",
       "12150    [-0.17980418, 0.6535479, -0.018154966, 0.14522...\n",
       "                               ...                        \n",
       "13596    [-0.21397658, 0.6811969, 0.042979807, 0.188356...\n",
       "12521    [-0.19500169, 0.690184, 0.03627778, 0.18370615...\n",
       "10333    [-0.16445737, 0.91079265, -0.22124012, 0.12149...\n",
       "12865    [-0.17456676, 0.44914293, 0.069868386, 0.12282...\n",
       "14180    [-0.29311618, 0.7813847, 0.014124836, 0.238057...\n",
       "Name: Texto Limpio, Length: 100, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hate_test_FV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 100)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se junta la data de entrenamiento\n",
    "X_train = np.concatenate((hate_train_FV.tolist(),no_hate_train_FV.tolist()),axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se junta las etiquetas de entrenamiento tanto hate y no hate\n",
    "Y_train = np.concatenate((hate_train[\"HATE\"].values,no_hate_train[\"HATE\"].values),axis=0)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se junta la data de test\n",
    "X_test = np.concatenate((hate_test_FV.tolist(),no_hate_test_FV.tolist()),axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se junta las etiquetas del test\n",
    "Y_test = np.concatenate((hate_test[\"HATE\"].values,no_hate_test[\"HATE\"].values),axis=0)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se usa la funcion svm con parametros de ajuste, entrenamos\n",
    "clasificador = svm.SVC(gamma=0.1,C=10)\n",
    "clasificador.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predecimos nuestra variable de test\n",
    "Y_pred = clasificador.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hallamos la precisión del modelo\n",
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       100\n",
      "           1       0.70      0.69      0.69       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.70      0.69      0.69       200\n",
      "weighted avg       0.70      0.69      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clasificador.predict(getFV(\"me gustaria que te mueras puto gay\").reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(clasificador.predict(getFV(\"te quiero mucho\").reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 30],\n",
       "       [31, 69]], dtype=int64)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mostramos la matriz de confusión\n",
    "confusion_matrix(Y_test,Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
